# General Approach

## Aims of this Dissertation

The overarching aim of this dissertation is to deepen our understanding of variability in a core social-cognitive ability, namely gaze following. In the [Introduction], I have highlighted calls for better (*i.e.,* valid, reliable, generalizable) social cognition measures. The projects included in this dissertation follow this call — and try to demonstrate that, even if demanding, methodological advancement is feasible. By focusing on an individual differences measure, this dissertation aims to question the conception that variation between participants equals noise and should be disregarded. By applying the newly designed gaze following measure, I hope to show-case how individual differences research on social cognition helps us to answer fundamental questions about the development, cognitive processes and universality of one of the most extraordinary human abilities. In the following, I will outline the role each of the four included studies play in reaching these overall objectives.

### Aims of Study I

Much of the existing social cognition research relies on study designs that were created for group-level analyses. Yet, many research questions focus on individual differences: for example, do siblings have a positive influence on children's social-cognitive development [@devine2018family; @peterson2000kindred; @perner1994theory; @stewart1983sibling]? How are gaze following and language abilities related [@okumura2017individual; @macdonald2013eye; @brooks2005development; @brooks2015connecting]? Can a child's perspective-taking ability be trained [@zhang2021worse; @ruffman2018variety; @lecce2014promoting]?

In order to relate cognitive abilities and external factors to each other, social cognition tasks need to be able to measure differences between children (or within children over a certain period of time). Tasks that are designed to do so remain rare. This study aimed at approaching this issue and described the development and validation of our new gaze following task, the TANGO (Task for Assessing iNdividual differences in Gaze understanding — Open). We have designed a playful study in which participants are asked to locate a balloon. The twist is that the participants cannot see the balloon itself. However, they see how another agent gazes out of a window, into the direction of the balloon. Participants have to follow the agent's gaze to locate the balloon. Their precision in doing so is measured continuously, namely in the distance between the actual target's location and their assumed location.

[Study I] consisted of three main parts. In the first part, we tested the task's usability in a sample of 3- to 5-year-old children and adults. We assessed whether the TANGO captured individual differences and compared data collected remotely vs. in-person (for the child sample). In the second part, we assessed whether these individual differences were reliable. We repeated data collection after two weeks and estimated retest-reliability and internal consistency. In the third part, we assessed the TANGO's validity. For its construct validity, we explored the relationship between the TANGO and variables of children's daily social environment. For its predictive validity, we examined the TANGO's relationship with a language measure six months later. Together, these findings thoroughly assessed the TANGO as a new task to measure individual differences in gaze following.

### Aims of Study II

[Study II] adopted the TANGO to examine three research questions related to individual differences: (1) how does gaze following develop across the lifespan, (2) how do people process gaze cues, and (3) how does gaze following relate to other (social-) cognitive abilities.

To answer the first question, we remotely collected data from 3- to 80-year-olds and examined changes in their ability to follow gaze. While previous gaze following research often focused on the youngest age in which children can follow gaze [e.g., @dentremont2000perceptual; @dentremont1997demonstration], we focused on the development (in precision) after this initial milestone.

Second, we developed a computational cognitive model to explain the underlying processes of how people process gaze. We hypothesized that participants observe the pupil location within the eye and calculate gaze vectors that point toward the attentional focus. As this process was likely to be noisy, individual differences were assumed in the participant's uncertainty surrounding this gaze vector. We judged the evidence for this gaze model by comparing it to two alternative explanations of the data: a center bias and a random guessing model. Due to its underlying geometrical features, the gaze model predicts that uncertainties around the gaze vector increase the further to the side an agent looks. We checked for this signature pattern in the data by assessing the participants' imprecision levels in each target bin.

Third, we tested whether an individual's precision in gaze following relates to other (social-) cognitive abilities. Consistent with our gaze model, we assessed whether gaze following was related to non-social vector following. To test this claim, we designed a new vector following task that matched the TANGO as closely as possible but within a non-social context. The vector following task relied on the concept of magnetism and asked children to locate a magnet based on the location of a gearwheel. Furthermore, we applied four tasks out of a \acr{ToM} task battery [@wellman2001metaanalysis] and two perspective-taking tasks [@flavell1981younga; @flavell1981development]. These comparisons aimed at disentangling the components that make up gaze following.

### Aims of Study III

The studies presented above relied on child samples from the Global North (Leipzig, Germany). Developmental theories often assume that central features of social cognition hold universally true across human cultures [@wellman2013universal]. Study III aimed at evaluating this claim: To broaden our perspective, we collected data of children's gaze following abilities from 17 diverse communities spanning five different continents. To our knowledge, this constitutes the largest international sample on children's gaze following.

First, we examined the developmental trajectory of gaze following across the communities. Second, we explored whether absolute differences in gaze following imprecision related to variables concerning the data collection mode and/or children's daily environments. Third, we checked whether the signature pattern predicted by our gaze model in Study II could be found in all communities studied. With this approach, we aimed to find out whether the process of children follow gaze is similar worldwide.

### Aims of Study IV

[Study IV] strengthens the basis for using the newly developed gaze following task for cross-cultural research. The paper had three main aims.

First, we described the process of designing the cross-cultural gaze following task (TANGO—CC). We aimed to provide a roadmap for other researchers how to pragmatically develop a new task that can be used for studying diverse communities.

Second, we provided a tutorial for how other researchers can use and customize the TANGO—CC according to their needs. This section aimed to highlight the components of the task that are constant and those that are variable and can be adapted to diverse languages and communities.

Third (and most importantly), we aimed at examining the TANGO—CC's reliability across diverse communities. While the psychometric properties of the TANGO were previously tested in one setting (Leipzig, Germany; [Study I]), we cannot simply generalize these findings and assume the task's validity and reliability based on a mono-cultural sample. For this purpose, we further analyzed the data set from [Study III]. We assessed performance across trial types, within- and between-community variation, and internal consistency measures in all of the 17 communities studied.

## Research Practices

Above, I have highlighted the theoretical approaches and aims of the publications included in this dissertation. All of these studies build upon the same underlying testing infrastructure. As this dissertation has a strong focus on methodological advances, I want to outline our main technological decisions within the process of designing this new testing infrastructure. In-depth information regarding each specific study can be found in the corresponding manuscripts in [Appendix A].

### Accessibility of Study Materials

@elson2023psychological figuratively stated that "psychological measures aren't toothbrushes" (p.1). The authors argue that psychological tasks are often used only a handful of times — by the same researcher(s) who designed the measure. However, this reluctance to share own measures and re-use measures of other researchers hinders cumulative science. Elson and colleagues, therefore, call for more transparency and standardization in the psychological tasks we implement and apply. We took this call seriously and strongly adhered to Open Science principles in the construction of our new standardized gaze following task.

The projects included in this dissertation pre-registered studies with their planned sample sizes, study procedures and planned analyses for hypothesis testing before data collection, as well as shared the study materials, analysis scripts and data sets after data collection. This dissertation and its included publications have published all related information in repositories on GitHub (<https://github.com>) and the Open Science Framework (<https://osf.io>; links leading to specific projects can be found in the respective manuscripts in the [Appendix A]). Articles were written in R Markdown which allows the user to combine continuous text and into one coherent document. Tracking analysis scripts and the manuscript texts in a version-controlled manner lets interested researchers retrace decisions and changes along the way. The newly implemented task(s) are openly available to other researchers to use and share as they wish. The source code of the website is also available via GitHub. By cloning the corresponding repository, motivated researchers can modify and further develop the task to their needs.

As the final project, [Study IV] incorporates refinements that have further optimized the usability of the gaze following task. While adapting the source code for cross-cultural stimulus presentation, I have refactored the code base (*i.e.*, improved the internal structure, readability, and maintainability of the software without altering its behavior or functionality). I have followed added comments to the code base using JSDoc (<https://jsdoc.app>), a markup language developed to document and annotate JavaScript source code files. Furthermore, I have collected frequently asked questions and created a manual for other researchers using the task (<https://ccp-odc.eva.mpg.de/tango-cc/manual.html>). These changes compared to the first version of the gaze following task hopefully serve to improve its sustainability over time.

### Presentation Mode

Before designing the gaze following task itself, we had to choose a presentation mode for the experimental stimuli. Many traditional developmental studies have designed interactive tasks for children in which they interact with the experimenter or their caregiver. This makes standardization difficult as experimenters have individual communication styles, might accidentally alter the instruction script due to memory gaps, or need replacement at some point (e.g., when temporary work contracts end). In addition, this approach makes scaling data collection difficult as training experimenters requires substantial temporal and financial resources. Since studies investigating individual differences rely on large sample sizes, we decided to take another route. We designed an online testing platform that hosts studies in all common web browsers. Please note that even though the task is programmed as a website, it does not require a working WiFi connection (for more information, see further down).

The design as an online study has several advantages. First, it allows for maximally standardized procedures as audio instructions are pre-recorded and automated. Second, data does not need to be entered manually or coded from video. Instead, the website stores response times and clicking behavior automatically. This greatly reduces potential biases and rater errors. Third, the presentation as a website allows for in-person and remote study participation. Families can choose whether they want to participate as before by coming to the research lab or kindergartens, or whether they want to participate from the comfort of their own home. In this case, no appointments or rooms need to be scheduled. The families receive a personalized invitation link and can access the online study whenever and wherever it suits them best. This increases the inclusiveness for families with busy schedules, longer traveling distances to the lab or children who might be shy to interact with strangers. While studies conducted in a research lab might be prone to over-study families with certain characteristics (e.g., families living closer by, having a higher SES or more free time), online studies might make study participation more accessible for a wider range of families — which, in turn, would increase the representativeness of the sample.

We have consciously chosen to implement an active behavioral measure as we wanted to circumvent issues in interpretability of implicit measures. For example, it is unclear whether looking time measures capture children's level of surprise, attention, memory formation or other cognitive processes, and whether they show convergent validity [@dorrenberg2018how; @aslin2007look]. While our outcome response does not provide a direct measure of underlying cognitive processes, it focuses on children's active behavior which might translate more directly into their actions in daily life.

The task itself is presented as an animated, interactive picture book. Audio instructions guide children through the task and provide a description of the presented events. Trial types build up on each other and familiarize children with the response format.

### Programming Framework

The online study was programmed in JavaScript (functionality of the website), HTML (content of the website), CSS (styling of the website) and PHP (server-side interaction for down-/ uploading data). We decided to refrain from using web development frameworks like Next.js or React. As the web development is a very fast moving domain with frequently appearing technology advances, projects relying on new frameworks often require regular monitoring and updates. Our goal was to create a durable code base that avoids breaking changes through large updates. Additionally, we aimed at keeping the code base as easily accessible as possible so that also researchers with less programming experience can read through and adjust the code. We reasoned that this could be better achieved by relying on the so-called "Vanilla JavaScript" without additional frameworks. An exception to this was an animation library we used. The GreenSock Animation Platform (GSAP; <https://gsap.com>) is a JavaScript library for industry-standard, high-performance web animations. However, GSAP is widely spread, well documented, and easy to read so including this library rather increases user friendliness. We used one further tool, namely a module bundler for JavaScript. Parcel (<https://parceljs.org>), and in later projects, webpack (<https://webpack.js.org>) tracked modules and dependencies, optimized website performance and enhanced the developer experience (e.g., by enabling a development server and hot reloading). However, please note that these bundlers only alter the source code on the sever-side — the functions, etc., defined in Vanilla JavaScript remain in their human-readable format.

During website development, we made use of the development server made available by the module bundler. This means that we could test the website on our local computer and only uploaded content to the web server once the website was fully implemented. The bundler builds a so-called "dist" folder that contains all website content in a compressed and optimized format. This folder is essential for both online and offline data collection. For online data collection, the dist folder gets uploaded to the web server and the study can be accessed under its corresponding URL. For offline data collection, a live server can be installed and hosts the dist folder, so that the website can be displayed on a computer without any internet connection. This is especially practical for data collection in settings with unreliable WiFi. Potentially, this might help for collecting data in communities living in remote villages, but also for data collection with children in (German) kindergartens as these institutions often do not have public internet connections or telephone reception.

### Data Processing

After a child completed the task, the website automatically saves all responses and response times. The website stores all click data and, if desired, some additional device information (e.g., touch screen yes/no, what type and version of web browser) in a text format. During initial development and the first published article (see [Study I]), we used JSON (JavaScript Object Notation) files which are commonly used for transmitting data in web applications. In later stages of the project (see [Study III]), we instead used CSV (Comma-Separated Values) files as these are more commonly used among psychology researchers. In these text files, each trial is represented by one row of data. Columns depict the collected variables, for example, subject id (anonymized), trial type, and response. If requested, a webcam recording can be captured that films the study participation via the front camera. We implemented this feature especially for remote data collection. After the consent of the caregivers, we could use the webcam recordings to ensure that indeed the children themselves carried out the task and did not get any help from their caregivers. Depending on the choice of the experimenter and the data collection setup, data will be uploaded to secure servers located within the Max Planck Institute for Evolutionary Anthropology, or will be downloaded to the testing device (e.g., tablet or computer).

Data pre-processing was greatly simplified as the study data does not require any further response coding. This saves time and effort by experimenters and reduces potential issues introduced by rater errors. Individual subject files were merged into one final data set using the programming language R. Data visualization and statistical analyses were conducted within the same program.
